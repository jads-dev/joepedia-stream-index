#!/usr/bin/env python3
"""Usage: stream-index.py [options]

Generates the stream index table for Joepedia from a spreadsheet.

Options:
    -h --help            Display this help.
    -i --input IN        The path to a CSV file to read the spreadsheet data
                         from, if downloading the data this will be written
                         to with the new data. [default: Joe - Streams.csv]
    -o --output OUT|-    The file to write to with the output wikitext.
                         Use - to print to the console.
                         [default: stream-index.txt]
    --overwrite-output   Allow overwriting the output wiki file.
    -d --download        Try to download the latest data from the spreadsheet,
                         requires an API key is set and the googleapiclient
                         library is installed.
    --overwrite-input    Allow overwriting the input CSV file if downloading.
    -u --update-wiki     Update the wiki page with the new output automatically.
                         Requires the pwiki library is installed.
    -q --quiet           Doesn't give output unless there is a problem, this
                         is implied if you output to stdout.

Uncommon Options:
    --google-api-key     The API key when downloading from google, if not
                         set the value of the GOOGLE_API_KEY environment
                         variable will be used.
    --spreadsheet-id ID  Specify the ID of the google spreadsheet to source the
                         data from, when downloading.
                         [default: 1ITQm2xYrVj7sycFsjwPSe8bbCFu3OJmPSGtzm3ZImRE]
    --skip-rows NUM      The number of rows to skip from the spreadsheet, to
                         ignore headers. [default: 7]
    --colors FILE        The JSON file to load a list of colors from.
                         [default: colors.json]
    --replacements FILE  The JSON file to load a list of text replacements from.
                         [default: replacements.json]
    --additional FILE    The JSON file to load a list of additional stream data
                         from. [default: additional_stream_data.json]
    --dry-run            Don't actually update the wiki, just show the output
                         for testing.
    --bot-name NAME      The name of the bot for updating
                         mediawiki. [default: joepedia-stream-index-bot]
    --bot-user USER      The user providing the bot password for updating
                         mediawiki, if not set the value of the
                         MEDIAWIKI_BOT_USER environment variable will be used.
    --bot-password PASS  The bot password for updating mediawiki, if not set
                         the value of the MEDIAWIKI_BOT_PASSWORD environment
                         variable will be used.

"""

import csv
import hashlib
import itertools
import json
import os
import sys
from collections.abc import Callable, Iterable, Mapping, Sequence
from contextlib import contextmanager
from dataclasses import dataclass
from datetime import datetime
from typing import IO

# Where this script can be found.
SCRIPT = "https://github.com/jads-dev/joepedia-stream-index"

# A warning added to the output to discourage manual edits.
WARNING = [
    "<!--",
    "  This content is generated by a script which can be found at ",
    f"  {SCRIPT}.",
    "  Manual changes **WILL BE LOST** when the script is next run, you almost",
    "  certainly want to re-run the script with new data, make changes to the ",
    "  script, or modify the StreamIndexEntry template instead.",
    "-->",
]

# Markers that are used to find and replace the table in the wiki page.
START_MARKER = "<!-- START GENERATED STREAM INDEX TABLE -->"
END_MARKER = "<!-- END GENERATED STREAM INDEX TABLE -->"


# Add a protocol to a link if it is missing, and put it under the given key.
def ensure_link_protocol(key: str, link: str):
    return (
        {key: link if link.startswith("https://") else f"https://{link}"}
        if link
        else {}
    )


# Apply replacements to a string to ensure it uses canonical names.
def canonicalise(replacements: Mapping[str, str], value: str):
    for target, replacement in replacements.items():
        value = value.replace(target, replacement)
    return value


# Obtain spreadsheet data using the google drive API.
def obtain(file_id: str, api_key: str | None):
    from googleapiclient.discovery import build

    with build("drive", "v3", developerKey=api_key) as drive:
        export = drive.files().export(fileId=file_id, mimeType="text/csv")
        data = export.execute()
        if not data:
            raise Exception("Could not obtain spreadsheet data.")
        else:
            return data.decode("utf-8")

@dataclass
class AdditionalRow:
    guest: Sequence[str]

    def as_arguments(self) -> Iterable[tuple[str, None | str | Mapping[str, str] | Iterable[str]]]:
        yield "guest", self.guest

empty_additional_stream_row = AdditionalRow([])

@dataclass
class Row:
    stream_index: int
    date: str
    part: int
    game: str
    game_index: int | None
    vods: Mapping[str, str]
    additional: AdditionalRow

    def as_arguments(
        self,
        multipart_streams: Mapping[int, int],
        color: Callable[[str], str]
    ) -> Iterable[tuple[str, None | str | Mapping[str, str] | Iterable[str]]]:
        yield "index", str(self.stream_index)
        yield "date", self.date
        last_part = multipart_streams.get(self.stream_index, None)
        if last_part:
            yield "part", str(self.part)
            if last_part == self.part:
                yield "last_part", "1"
        yield "game", self.game
        yield "game_index", str(self.game_index) if self.game_index else None
        yield "vod", self.vods
        yield "color", color(self.game)
        yield from self.additional.as_arguments()


# Get an int from a string.
def numerical(value: str | None) -> int | None:
    if not value:
        return None
    else:
        try:
            return int(value, 10)
        except ValueError:
            stripped = value.strip("?! ~")
            if stripped != value:
                return numerical(stripped)
            else:
                raise


# Read CSV data in and create a map in a standard format for it.
def read_and_standardise(
    file: IO,
    skip_rows: int,
    replacements: Mapping[str, str],
    additional_stream_data: Mapping[int, AdditionalRow],
) -> Iterable[Row]:
    reader = csv.reader(file, delimiter=",")
    previous_index, previous_date = None, None
    part = 1
    for row in itertools.islice(reader, skip_rows + 1, None):
        [
            index,
            date,
            other_date,
            game,
            game_index,
            vod_with_chat,
            _,
            _,
            vod_without_chat,
            *_,
        ] = row

        # Skip graph at the end.
        if (not index and date) or other_date == "(Today)":
            continue

        vods = {
            **ensure_link_protocol("with_chat", vod_with_chat),
            **ensure_link_protocol("without_chat", vod_without_chat),
        }

        current_index = int(index, 10) if index else previous_index
        current_date = date if date else previous_date
        part = part + 1 if not index else 1

        # Skip if we don't have core details still.
        if current_index is None or current_date is None:
            continue

        # Skip joke Signalis entries.
        if current_index < 300 and game == "Signalis":
            continue

        additional = additional_stream_data.get(
            current_index,
            empty_additional_stream_row
        )

        yield Row(
            current_index,
            datetime.strptime(current_date, "%a, %m/%d/%Y").strftime(
                "%Y-%m-%d"
            ),
            part,
            canonicalise(replacements, game),
            numerical(game_index),
            vods,
            additional
        )

        previous_index, previous_date = current_index, current_date


# A hash that should produce the same number for a string each time.
def stable_hash(key: str) -> int:
    hash = hashlib.md5(bytes(key, "UTF-8"), usedforsecurity=False)
    return int.from_bytes(hash.digest(), signed=False)


# Get a color using the hash of the string, giving the same color each time as
# long as the length of the color list doesn't change.
def color_picker(colors: Sequence[str]) -> Callable[[str], str]:
    max = len(colors)

    def color_for_name(name: str) -> str:
        return colors[stable_hash(name) % max]

    return color_for_name


# Turn the value into template arguments, if there are multiple, indexing
# them (for lists) or suffixing them (for maps).
def as_template_argument(
    key: str,
    value: str | Mapping[str, str] | Iterable[str]
) -> Iterable[str]:
    if isinstance(value, Mapping):
        for subkey, subvalue in value.items():
            yield f"{key}_{subkey}={subvalue}"
    elif not isinstance(value, str) and isinstance(value, Iterable):
        for index, subvalue in enumerate(value):
            index_str = f"{index + 1}" if index > 0 else ""
            yield f"{key}{index_str}={subvalue}"
    else:
        yield f"{key}={value}"



# Generate wikitext given the standardised rows from the CSV.
def generate_wiki_source(
    data_source_id: str,
    rows: Sequence[Row],
    colors: Sequence[str],
):
    data_source_url = f"https://docs.google.com/spreadsheets/d/{data_source_id}"
    data_attribution = (
        "sourced from a spreadsheet maintained {{Attribution|Falco}}"
        f"<ref>[{data_source_url} Falco’s Spreadsheet of Joe content].</ref>"
    )
    script_attribution = (
        "and processed using a script originally written "
        "{{Attribution|JayUplink}}"
        f"<ref>[{SCRIPT} “joepedia-stream-index” on GitHub].</ref>"
    )
    attributions = ", ".join([data_attribution, script_attribution])

    multipart_streams = {row.stream_index for row in rows if row.part > 1 }
    last_parts = { index: max(row.part for row in rows if row.stream_index == index) for index in multipart_streams }

    color_for_name = color_picker(colors)

    yield START_MARKER
    yield from WARNING
    yield """<div style="display: flex; justify-content: center;">"""
    yield """{| class="wikitable" """
    yield f"""  |+ style="caption-side:bottom;"|This data is {attributions}."""
    yield "|-"
    yield "! # !! Date !! Game !! No. in Series !! Available VODs"
    yield ""

    for row in reversed(rows):
        arguments = "|".join(
            itertools.chain.from_iterable(
                as_template_argument(key, value)
                for (key, value) in row.as_arguments(last_parts, color_for_name)
                if value
            )
        )
        yield f"  {{{{StreamIndexEntry|{arguments}}}}}"

    yield "|}"
    yield "</div>"
    yield from WARNING
    yield END_MARKER


# Open, only allowing overwriting if the given argument is provided.
@contextmanager
def open_overwrite(
    filename: str, arguments: Mapping[str, str], overwrite_arg_name: str
):
    try:
        yield open(filename, "w" if arguments[overwrite_arg_name] else "x")
    except FileExistsError:
        print(
            f"Error: The file “{file}” already exists, use the "
            f"“{overwrite_arg_name}” argument if you wish to overwrite it.",
            file=sys.stderr,
        )
        sys.exit(2)


# Open and read as JSON.
def open_json(arguments: Mapping[str, str], file_arg_name: str):
    filename = arguments[file_arg_name]
    try:
        with open(filename, "r") as file:
            return json.load(file)
    except FileNotFoundError:
        print(
            f"Error: The file “{filename}” does not exists, use the "
            f"“{file_arg_name}” argument if you wish to change what file to "
            "use.",
            file=sys.stderr,
        )
        sys.exit(2)


# Update the wiki page on the wiki.
def update_wiki_page(
    name: str,
    user: str,
    password: str,
    page_name: str,
    wiki_text: str,
    reason: str,
    dry_run: bool,
    quiet: bool,
):
    from pwiki.wiki import Wiki

    wiki = Wiki(
        "wiki.jads.stream",
        f"{user}@{name}",
        password,
        None, #type: ignore # Bad types on the lib.
        "https://wiki.jads.stream/api.php",
    )

    old_text = wiki.page_text(page_name)
    before, start_marker, rest = old_text.partition(START_MARKER)
    if not start_marker:
        raise Exception(
            f"Could not find the old table start marker (“{START_MARKER}”) on the page."
        )
    _old_table, end_marker, after = old_text.partition(END_MARKER)
    if not end_marker:
        raise Exception(
            f"Could not find the old table start marker (“{START_MARKER}”) on the page."
        )
    new_text = f"{before}{wiki_text}{after}"

    if old_text != new_text:
        summary = f"{name}: Updated because {reason}."
        if dry_run:
            print(f"{name}: Dry run, not actually updating, would have edited to:")
            print(new_text)
        else:
            wiki.edit(page_name, new_text, summary)
            if not quiet:
                print(summary)
    else:
        if not quiet:
            print(f"{name}: Update tried because {reason}, but no changes needed.")


if __name__ == "__main__":
    from docopt import docopt

    arguments = docopt(__doc__)

    download: bool = arguments["--download"]
    input_file: str = arguments["--input"]
    data_source_id: str = arguments["--spreadsheet-id"]
    output_file: str = arguments["--output"]
    update_wiki: bool = arguments["--update-wiki"]

    replacements: Mapping[str, str] = open_json(arguments, "--replacements")
    colors: Sequence[str] = open_json(arguments, "--colors")
    additional_stream_data_json = open_json(arguments, "--additional")
    additional_stream_data = { int(key, 10): AdditionalRow(**value)
        for (key, value) in additional_stream_data_json.items()
    }

    quiet = arguments["--quiet"] or output_file == "-"

    if download:
        api_key = arguments["--google-api-key"] or os.environ.get(
            "GOOGLE_API_KEY", None
        )
        if not api_key:
            print(
                "An API key must be provided with either “--google-api-key” or "
                "the “GOOGLE_API_KEY” environment variable when downloading.",
                file=sys.stderr,
            )
            sys.exit(2)
        data = obtain(data_source_id, api_key)
        with open_overwrite(input_file, arguments, "--overwrite-input") as file:
            file.write(data)
        if not quiet:
            print(f"Written source data to “{input_file}”.")

    with open(input_file, "r") as file:
        rows = list(
            read_and_standardise(
                file,
                int(arguments["--skip-rows"], base=10),
                replacements,
                additional_stream_data,
            )
        )

    wikitext_lines = generate_wiki_source(data_source_id, rows, colors)
    wikitext = "\n".join(wikitext_lines)

    if quiet:
        print(wikitext)
    else:
        print(f"Written wikitext to “{output_file}”.")
        with open_overwrite(output_file, arguments, "--overwrite-output") as file:
            file.write(f"{wikitext}\n")

    if update_wiki:
        user: str | None = (
            arguments["--bot-user"] or
            os.environ.get("MEDIAWIKI_BOT_USER", None)
        )
        password: str | None = (
            arguments["--bot-password"] or
            os.environ.get("MEDIAWIKI_BOT_PASSWORD", None)
        )

        if user is None or password is None:
            print(
                "To update the wiki page a user and password must be given for the"
                "bot, set the “--bot-user” and “--bot-password” options or the "
                "“MEDIAWIKI_BOT_USER” and “MEDIAWIKI_BOT_PASSWORD” environment "
                "variables.",
                file=sys.stderr,
            )
            sys.exit(2)

        update_wiki_page(
            arguments["--bot-name"],
            user,
            password,
            "Stream Index",
            wikitext,
            os.environ.get("UPDATE_REASON", "the script was manually run"),
            arguments["--dry-run"],
            quiet,
        )

    if not quiet:
        print("Success")
