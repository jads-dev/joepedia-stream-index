#!/usr/bin/env python3
"""Usage: stream-index.py [options]

Generates the stream index table for Joepedia from a spreadsheet.

Options:
    -h --help            Display this help.
    -i --input IN        The path to a CSV file to read the spreadsheet data
                         from, if downloading the data this will be written
                         to with the new data. [default: Joe - Streams.csv]
    -o --output OUT|-    The file to write to with the output wikitext.
                         Use - to print to the console.
                         [default: stream-index.txt]
    --overwrite-output   Allow overwriting the output wiki file.
    -d --download        Try to download the latest data from the spreadsheet,
                         requires an API key is set and the googleapiclient
                         library is installed.
    --overwrite-input    Allow overwriting the input CSV file if downloading.
    -u --update-wiki     Update the wiki page with the new output automatically.
                         Requires the pwiki library is installed.
    -q --quiet           Doesn't give output unless there is a problem, this
                         is implied if you output to stdout.
    -l --lookup          Try to look up game data from IGDB, requires a client
                         ID and secret are set and rauth and igdb-api-v4
                         libraries are installed.

Uncommon Options:
    --google-api-key     The API key when downloading from google, if not
                         set the value of the GOOGLE_API_KEY environment
                         variable will be used.
    --spreadsheet-id ID  Specify the ID of the google spreadsheet to source the
                         data from, when downloading.
                         [default: 1ITQm2xYrVj7sycFsjwPSe8bbCFu3OJmPSGtzm3ZImRE]
    --skip-rows NUM      The number of rows to skip from the spreadsheet, to
                         ignore headers. [default: 7]
    --colors FILE        The JSON file to load a list of colors from.
                         [default: colors.json]
    --replacements FILE  The JSON file to load a list of text replacements from.
                         [default: replacements.json]
    --additional FILE    The JSON file to load a list of additional stream data
                         from. [default: additional_stream_data.json]
    --game-slugs FILE    The JSON file to load a mapping of game names to IGDB
                         slugs from. [default: slugs.json]
    --dry-run            Don't actually update the wiki, just show the output
                         for testing.
    --local-json         Get JSON files from the local filesystem rather than
                         the wiki.
    --bot-name NAME      The name of the bot for accessing and updating
                         mediawiki. [default: joepedia-stream-index-bot]
    --bot-user USER      The user providing the bot password for accessing
                         and updating mediawiki, if not set the value of the
                         MEDIAWIKI_BOT_USER environment variable will be used.
    --bot-password PASS  The bot password for accessing and updating mediawiki,
                         if not set the value of the MEDIAWIKI_BOT_PASSWORD
                         environment variable will be used.
    --igdb-id ID         The client ID for IGDB's API, if not set the value of
                         the IGDB_ID environment variable will be used.
    --igdb-secret SECRET The secret for IGDB's API, if not set the value of the
                         IGDB_SECRET environment variable will be used.
"""

from __future__ import annotations
from typing import TYPE_CHECKING, Optional, Tuple
import csv
import hashlib
import itertools
import json
import os
import sys
from collections.abc import Callable, Iterable, Mapping, Sequence
from contextlib import contextmanager
from dataclasses import dataclass
from datetime import datetime
from typing import IO
from dotenv import load_dotenv

load_dotenv()

if TYPE_CHECKING:
    from pwiki.wiki import Wiki
    from igdb.wrapper import IGDBWrapper

# Where this script can be found.
SCRIPT = "https://github.com/jads-dev/joepedia-stream-index"

# A warning added to the output to discourage manual edits.
WARNING = [
    "<!--",
    "  This content is generated by a script which can be found at ",
    f"  {SCRIPT}.",
    "  Manual changes **WILL BE LOST** when the script is next run, you almost",
    "  certainly want to re-run the script with new data, make changes to the ",
    "  script, or modify the StreamIndexEntry template instead.",
    "-->",
]

# Markers that are used to find and replace the table in the wiki page.
START_MARKER = "<!-- START GENERATED STREAM INDEX TABLE -->"
END_MARKER = "<!-- END GENERATED STREAM INDEX TABLE -->"


# Authentication for a wiki.
@dataclass
class WikiAuth:
    name: str
    user: str
    password: str


# A lazy loader for wiki access.
# This assumes name/password don't change.
class LazyWiki:
    wiki: Wiki | None

    def __init__(self):
        self.wiki = None

    def load(self, auth: WikiAuth) -> Wiki:
        if self.wiki is not None:
            return self.wiki
        else:
            from pwiki.wiki import Wiki

            self.wiki = Wiki(
                "wiki.jads.stream",
                f"{auth.user}@{auth.name}",
                auth.password,
                None,  # type: ignore # Bad types on the lib.
                "https://wiki.jads.stream/api.php",
            )
            return self.wiki


lazy_wiki = LazyWiki()


class GameResolver:
    igdb: Optional[IGDBWrapper] = None
    cache: Mapping[str, str]

    def __init__(self, slugs, auth: Optional[Tuple[str, str]] = None):
        self.cache = slugs
        if auth is not None:
            from igdb.wrapper import IGDBWrapper
            from rauth import OAuth2Service

            (id, secret) = auth
            twitch = OAuth2Service(
                client_id=id,
                client_secret=secret,
                name="twitch",
                authorize_url="https://id.twitch.tv/oauth2/authorize",
                access_token_url="https://id.twitch.tv/oauth2/token",
                base_url="https://id.twitch.tv/",
            )
            accessToken = twitch.get_access_token(
                decoder=json.loads, data={"grant_type": "client_credentials"}
            )
            self.igdb = IGDBWrapper(id, accessToken)
        else:
            self.igdb = None

    def _lookup(self, game_name: str) -> str | None:
        if self.igdb:
            from igdb.igdbapi_pb2 import GameResult

            response = self.igdb.api_request(
                "games.pb", f'fields slug, name; limit 1; search "{game_name}";'
            )
            result = GameResult()
            result.ParseFromString(response)
            if len(result.games) > 0:
                [game] = result.games
                print(
                    f"Matched “{game_name}” to “{game.slug}”.",
                    file=sys.stderr,
                )
                return game.slug
            else:
                print(
                    f"Could not find a game on IGDB to match “{game_name}”.",
                    file=sys.stderr,
                )
        else:
            print(
                f"No slug available for “{game_name}”.",
                file=sys.stderr,
            )
        return None

    def lookup(self, game_name: str) -> str | None:
        # Value can intentionally be null so we check the key not the value.
        if game_name in self.cache:
            cached = self.cache.get(game_name)
            return cached
        else:
            result = self._lookup(game_name)
            self.cache[game_name] = result
            return result


# Add a protocol to a link if it is missing.
def ensure_link_protocol(link: str) -> str:
    return link if link.startswith("https://") else f"https://{link}"


# Apply replacements to a string to ensure it uses canonical names.
def canonicalise(replacements: Mapping[str, str], value: str) -> str:
    for target, replacement in replacements.items():
        value = value.replace(target, replacement)
    return value


# Obtain spreadsheet data using the google drive API.
def obtain(file_id: str, api_key: str | None) -> str:
    from googleapiclient.discovery import build

    with build("drive", "v3", developerKey=api_key) as drive:
        export = drive.files().export(fileId=file_id, mimeType="text/csv")
        data = export.execute()
        if not data:
            raise Exception("Could not obtain spreadsheet data.")
        else:
            return data.decode("utf-8")


@dataclass
class AdditionalRow:
    guest: Sequence[str]

    def as_arguments(
        self,
    ) -> Iterable[tuple[str, None | str | Mapping[str, str] | Iterable[str]]]:
        yield "guest", self.guest


empty_additional_stream_row = AdditionalRow([])


@dataclass
class Row:
    stream_index: int
    date: str
    part: int
    game: str
    igdb_slug: str | None
    game_index: int | None
    vods: Mapping[str, str]
    additional: AdditionalRow

    def as_arguments(
        self, multipart_streams: Mapping[int, int], color: Callable[[str], str]
    ) -> Iterable[tuple[str, None | str | Mapping[str, str] | Iterable[str]]]:
        yield "index", str(self.stream_index)
        yield "date", self.date
        last_part = multipart_streams.get(self.stream_index, None)
        if last_part:
            yield "part", str(self.part)
            if last_part == self.part:
                yield "last_part", "1"
        yield "game", self.game
        yield "igdb_slug", self.igdb_slug
        yield "game_index", str(self.game_index) if self.game_index else None
        yield "vod", self.vods
        yield "color", color(self.game)
        yield from self.additional.as_arguments()


# Get an int from a string.
def numerical(value: str | None) -> int | None:
    if not value:
        return None
    else:
        try:
            return int(value, 10)
        except ValueError:
            stripped = value.strip("?! ~")
            if stripped != value:
                return numerical(stripped)
            else:
                raise


# Read CSV data in and create a map in a standard format for it.
def read_and_standardise(
    file: IO,
    gameResolver: GameResolver,
    skip_rows: int = 0,
    replacements: Mapping[str, str] | None = None,
    additional_stream_data: Mapping[int, AdditionalRow] | None = None,
) -> Iterable[Row]:
    if replacements is None:
        replacements = {}
    if additional_stream_data is None:
        additional_stream_data = {}
    reader = csv.reader(file, delimiter=",")
    previous_index, previous_date = None, None
    part = 1
    for row in itertools.islice(reader, skip_rows + 1, None):
        try:
            [
                index,
                date,
                other_date,
                game,
                game_index,
                _,
                vod_with_chat,
                _,
                _,
                vod_without_chat,
                *_,
            ] = row

            # Skip graph at the end.
            if (not index and date) or game == "(Today)":
                continue

            vods = {
                key: ensure_link_protocol(value)
                for (key, value) in [
                    ("with_chat", vod_with_chat),
                    ("without_chat", vod_without_chat),
                ]
                if value
            }

            current_index = int(index, 10) if index else previous_index
            current_date = date if date else previous_date
            part = part + 1 if not index else 1

            # Skip if we don't have core details still.
            if current_index is None or current_date is None:
                continue

            # Skip joke Signalis entries.
            if current_index < 300 and game == "Signalis":
                continue

            additional = additional_stream_data.get(
                current_index, empty_additional_stream_row
            )

            row = Row(
                current_index,
                datetime.strptime(current_date, "%a, %m/%d/%Y").strftime("%Y-%m-%d"),
                part,
                canonicalise(replacements, game),
                None,
                numerical(game_index),
                vods,
                additional,
            )

            if (
                row.game_index is not None
                and row.game_index > 21
                and row.game == "Umineko When They Cry - Question Arcs"
            ):
                row.game = "Umineko When They Cry - Answer Arcs"

            row.igdb_slug = gameResolver.lookup(row.game)

            yield row

            previous_index, previous_date = current_index, current_date
        except Exception:
            print(
                f"Error: could not parse row: {row}",
                file=sys.stderr,
            )
            raise


# A hash that should produce the same number for a string each time.
def stable_hash(key: str) -> int:
    hash = hashlib.md5(bytes(key, "UTF-8"), usedforsecurity=False)
    return int.from_bytes(hash.digest(), signed=False)


# Get a color using the hash of the string, giving the same color each time as
# long as the length of the color list doesn't change.
def color_picker(colors: Sequence[str]) -> Callable[[str], str]:
    max = len(colors)

    def color_for_name(name: str) -> str:
        return colors[stable_hash(name) % max]

    return color_for_name


# Turn the value into template arguments, if there are multiple, indexing
# them (for lists) or suffixing them (for maps).
def as_template_argument(
    key: str, value: str | Mapping[str, str] | Iterable[str]
) -> Iterable[str]:
    if isinstance(value, Mapping):
        for subkey, subvalue in value.items():
            yield f"{key}_{subkey}={subvalue}"
    elif not isinstance(value, str) and isinstance(value, Iterable):
        for index, subvalue in enumerate(value):
            index_str = f"{index + 1}" if index > 0 else ""
            yield f"{key}{index_str}={subvalue}"
    else:
        yield f"{key}={value}"


# Generate wikitext given the standardised rows from the CSV.
def generate_wiki_source(
    data_source_id: str,
    rows: Sequence[Row],
    colors: Sequence[str],
):
    data_source_url = f"https://docs.google.com/spreadsheets/d/{data_source_id}"
    data_attribution = (
        "sourced from a spreadsheet maintained {{Attribution|Falco}}"
        f"<ref>[{data_source_url} Falco’s Spreadsheet of Joe content].</ref>"
    )
    script_attribution = (
        "and processed using a script originally written "
        "{{Attribution|JayUplink}}"
        f"<ref>[{SCRIPT} “joepedia-stream-index” on GitHub].</ref>"
    )
    attributions = ", ".join([data_attribution, script_attribution])

    multipart_streams = {row.stream_index for row in rows if row.part > 1}
    last_parts = {
        index: max(row.part for row in rows if row.stream_index == index)
        for index in multipart_streams
    }

    color_for_name = color_picker(colors)

    yield START_MARKER
    yield from WARNING
    yield """<div style="display: flex; justify-content: center;">"""
    yield """{| class="wikitable" """
    yield f"""  |+ style="caption-side:bottom;"|This data is {attributions}."""
    yield "|-"
    yield "! # !! Date !! Game !! No. in Series !! Available VODs"
    yield ""

    for row in reversed(rows):
        arguments = "|".join(
            itertools.chain.from_iterable(
                as_template_argument(key, value)
                for (key, value) in row.as_arguments(last_parts, color_for_name)
                if value
            )
        )
        yield f"  {{{{StreamIndexEntry|{arguments}}}}}"

    yield "|}"
    yield "</div>"
    yield from WARNING
    yield END_MARKER


# Open, only allowing overwriting if the given argument is provided.
@contextmanager
def open_overwrite(
    filename: str, arguments: Mapping[str, str], overwrite_arg_name: str
):
    try:
        yield open(filename, "w" if arguments[overwrite_arg_name] else "x")
    except FileExistsError:
        print(
            f"Error: The file “{file}” already exists, use the "
            f"“{overwrite_arg_name}” argument if you wish to overwrite it.",
            file=sys.stderr,
        )
        sys.exit(2)


# Open and read as JSON.
def open_json(
    arguments: Mapping[str, str],
    file_arg_name: str,
    page_name: str,
    auth: WikiAuth | None = None,
    local_json: bool = False,
):
    filename = arguments[file_arg_name]
    if auth is None:
        try:
            with open(filename, "r") as file:
                return json.load(file)
        except FileNotFoundError:
            print(
                f"Error: The file “{filename}” does not exists, use the "
                f"“{file_arg_name}” argument if you wish to change what file to "
                "use, or don't use --local-json to look on the wiki.",
                file=sys.stderr,
            )
            sys.exit(2)
    else:
        if auth is None:
            print(
                "To access wiki pages a user and password must be given for "
                "the bot, set the “--bot-user” and “--bot-password” options or "
                "the “MEDIAWIKI_BOT_USER” and “MEDIAWIKI_BOT_PASSWORD” "
                "environment variables, or --local-json to look for local "
                "files rather than on the wiki.",
                file=sys.stderr,
            )
            sys.exit(2)
        wiki = lazy_wiki.load(auth)
        file_page_name = f"{page_name}/{filename}"
        raw_json = wiki.page_text(file_page_name)
        if raw_json is None:
            print(
                f"Error: The wiki page “{file_page_name}” does not exists, use "
                f"the “{file_arg_name}” argument if you wish to change what "
                "page to use, or --local-json to look for local files rather "
                "than on the wiki.",
                file=sys.stderr,
            )
            sys.exit(2)
        else:
            return json.loads(raw_json)


# Update the wiki page on the wiki.
def update_wiki_page(
    auth: WikiAuth,
    page_name: str,
    wiki_text: str,
    reason: str,
    dry_run: bool,
    quiet: bool,
):
    wiki = lazy_wiki.load(auth)

    old_text = wiki.page_text(page_name)
    before, start_marker, rest = old_text.partition(START_MARKER)
    if not start_marker:
        raise Exception(
            f"Could not find the old table start marker (“{START_MARKER}”) on the page."
        )
    _old_table, end_marker, after = old_text.partition(END_MARKER)
    if not end_marker:
        raise Exception(
            f"Could not find the old table start marker (“{START_MARKER}”) on the page."
        )
    new_text = f"{before}{wiki_text}{after}"

    if old_text != new_text:
        summary = f"{auth.name}: Updated because {reason}."
        if dry_run:
            print(f"{auth.name}: Dry run, not actually updating, would have edited to:")
            print(new_text)
        else:
            wiki.edit(page_name, new_text, summary)  # type: ignore # Bad types on the lib.
            if not quiet:
                print(summary)
    else:
        if not quiet:
            print(f"{auth.name}: Update tried because {reason}, but no changes needed.")


if __name__ == "__main__":
    from docopt import docopt

    arguments = docopt(__doc__)

    page_name = "Stream Index"

    download: bool = arguments["--download"]
    input_file: str = arguments["--input"]
    data_source_id: str = arguments["--spreadsheet-id"]
    output_file: str = arguments["--output"]
    update_wiki: bool = arguments["--update-wiki"]
    local_json: bool = arguments["--local-json"]
    lookup: bool = arguments["--lookup"]

    user: str | None = arguments["--bot-user"] or os.environ.get(
        "MEDIAWIKI_BOT_USER", None
    )
    password: str | None = arguments["--bot-password"] or os.environ.get(
        "MEDIAWIKI_BOT_PASSWORD", None
    )

    auth: WikiAuth | None = (
        None
        if user is None or password is None
        else WikiAuth(
            arguments["--bot-name"],
            user,
            password,
        )
    )

    replacements: Mapping[str, str] = open_json(
        arguments, "--replacements", page_name, auth, local_json
    )
    colors: Sequence[str] = open_json(
        arguments, "--colors", page_name, auth, local_json
    )
    additional_stream_data_json = open_json(
        arguments, "--additional", page_name, auth, local_json
    )
    game_slugs = open_json(arguments, "--game-slugs", page_name, auth, local_json)
    additional_stream_data = {
        int(key, 10): AdditionalRow(**value)
        for (key, value) in additional_stream_data_json.items()
    }
    api_key = arguments["--google-api-key"] or os.environ.get("GOOGLE_API_KEY", None)
    igdb_id = arguments["--igdb-id"] or os.environ.get("IGDB_ID", None)
    igdb_secret = arguments["--igdb-secret"] or os.environ.get("IGDB_SECRET", None)

    if lookup:
        if not igdb_id or not igdb_secret:
            print(
                "An IGDB client id and secret must be provided with either "
                "“--igdb-id”/“--igdb-secret” or the “IGDB_ID”/“IGDB_SECRET” "
                "environment variables when lookup is enabled.",
                file=sys.stderr,
            )
            sys.exit(2)
    gameResolver = GameResolver(game_slugs, (igdb_id, igdb_secret) if lookup else None)

    quiet = arguments["--quiet"] or output_file == "-"

    if download:
        if not api_key:
            print(
                "An API key must be provided with either “--google-api-key” or "
                "the “GOOGLE_API_KEY” environment variable when downloading.",
                file=sys.stderr,
            )
            sys.exit(2)
        data = obtain(data_source_id, api_key)
        with open_overwrite(input_file, arguments, "--overwrite-input") as file:
            file.write(data)
        if not quiet:
            print(f"Written source data to “{input_file}”.")

    with open(input_file, "r") as file:
        rows = list(
            read_and_standardise(
                file,
                gameResolver,
                int(arguments["--skip-rows"], base=10),
                replacements,
                additional_stream_data,
            )
        )

    wikitext_lines = generate_wiki_source(data_source_id, rows, colors)
    wikitext = "\n".join(wikitext_lines)

    if quiet:
        print(wikitext)
    else:
        print(f"Written wikitext to “{output_file}”.")
        with open_overwrite(output_file, arguments, "--overwrite-output") as file:
            file.write(f"{wikitext}\n")

    if update_wiki:
        if auth is None:
            print(
                "To update the wiki page a user and password must be given for "
                "the bot, set the “--bot-user” and “--bot-password” options or "
                "the “MEDIAWIKI_BOT_USER” and “MEDIAWIKI_BOT_PASSWORD” "
                "environment variables.",
                file=sys.stderr,
            )
            sys.exit(2)

        update_wiki_page(
            auth,
            page_name,
            wikitext,
            os.environ.get("UPDATE_REASON", "the script was manually run"),
            arguments["--dry-run"],
            quiet,
        )

    if not quiet:
        print("Success")
